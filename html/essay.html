<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Essay</title>
    <link rel="stylesheet" href="../css/style.css" />
    <link rel="stylesheet" href="../css/essay.css" />

    <link rel="stylesheet" href="../css/blog.css" />
  </head>
  <body>
    <header>
      <nav>
        <script id="replace_with_navbar" src="../js/nav.js"></script>
      </nav>
    </header>

    <section class="essays" id="essays">
      <nav class="secondarynav" id="secondarynav">
        <a href="#essays" class="active">Essay 1</a>
        <a href="#essay2">Essay 2</a>
        <a href="#bib">Bibliography</a>
      </nav>

      <h2 class="heading">
        <span>Ethics</span> Of <span>UI & UX</span> On The Website:
        <span>News24</span>
      </h2>
      <main class="essay-container">
        <p class="essayText">
          The idea that UI and UX on a website are an indicator of manipulation
          tactics in this technology era has been argued among people for years
          as there have been arguments as to how the UI and UX of a website have
          been constructed to be unethical towards a user on the website. It has
          been stated the UI and UX of websites are unethical in their
          construction to manipulate the user to stay on the website to create
          traffic while exploiting the users’ behaviours. By investigating the
          system of News24’s website and the work of Marc Hassenzahl and Noam
          Tractinsky in “User experience - a research agenda” and studying “The
          Ethics of User Experience Design” by Peter Vistisen and Thessa Jensen.
          This essay will attempt to justify whether the construction of the
          website News24 is ethical through its UI and UX.
        </p>
        <p class="essayText">
          The term ethics/ethical refers to the principles and values of a
          person or group that one can use in determining whether an action is
          right, wrong, or even morally justified. (Dictionary.com 2023) From
          this understanding, it can be understood that ethics is about making
          informed decisions based on a person’s judgement to be better and more
          responsible. Therefore, through the understanding of ethics, we can
          determine whether News24 has made ethical design choices for the user.
        </p>
        <p class="essayText">
          News24 is a media company in South Africa that provides information on
          news, analysis, business, sports, entertainment and many more. News24
          focus on local and international news that is accurate and timely
          information to its users. News24 provides its information through a
          website and mobile app, which allows for easy accessibility and use to
          the user. News24 displays video and audio content which allows for
          interactive tools and multimedia presentations.
        </p>
        <p class="essayText">
          The role of the user interface is to provide ways in which the user
          can interact with the website to improve a user’s experience.
          (Interaction design foundation 2023.) Looking at News24’s website
          there are key UI features that stand out. First is the Homepage, which
          uses a white background to contrast with the larger images and bolder
          headline, making it easier for the user to visually read and go
          through to find what they are looking for or what interest them. It
          uses a grid layout to keep all the different types of articles in a
          consistent layout and keeps everything aligned for the user. Second is
          the navigation bar, it is placed close to the top of the page,
          allowing the user to browse through the category to find the section
          they are interested in making it to easily navigate the website as the
          users can also search for specific topics using the search bar.
          Further into the UI of the website is seen on the article pages. The
          article page is when the user clicks on an article to read further.
          The design is made so that it is easy to read, with clear typography
          and plenty of white space and using images and videos to break up the
          text. This allows the user to stay focused on the article during the
          short and consistent sentences. Another UI is the interactive features
          on the website. As it uses polls, quizzes, and live blogs, which are
          designed to encourage user engagement so they can feel as if they are
          part taking in providing the news while allowing for an immersive
          experience. The last key UI feature is News24 optimization for all
          devices The UI is responsive in design as it adjusts to the size of
          the screen. This ensures that users can easily access the website on
          any device. These are the key UI feature that allows for a better user
          experience on the website. This concept is iterated by Interaction
          Design Foundation when they explain the concept of “Good UI”
          (Interaction design foundation 2023)by explaining how UI must be kept
          simple and aligned for the user to that it is easy and simple to use
          while allowing the user to stay focused on the task they have. Thus,
          showing how News24 uses UI successfully for easy and simple user
          interaction and understanding.
        </p>
        <p class="essayText">
          The role of the user interface is to provide ways in which the user
          can interact with the website to improve a user’s experience.
          (Interaction design foundation 2023.) Looking at News24’s website
          there are key UI features that stand out. First is the Homepage, which
          uses a white background to contrast with the larger images and bolder
          headline, making it easier for the user to visually read and go
          through to find what they are looking for or what interest them. It
          uses a grid layout to keep all the different types of articles in a
          consistent layout and keeps everything aligned for the user. Second is
          the navigation bar, it is placed close to the top of the page,
          allowing the user to browse through the category to find the section
          they are interested in making it to easily navigate the website as the
          users can also search for specific topics using the search bar.
          Further into the UI of the website is seen on the article pages. The
          article page is when the user clicks on an article to read further.
          The design is made so that it is easy to read, with clear typography
          and plenty of white space and using images and videos to break up the
          text. This allows the user to stay focused on the article during the
          short and consistent sentences. Another UI is the interactive features
          on the website. As it uses polls, quizzes, and live blogs, which are
          designed to encourage user engagement so they can feel as if they are
          part taking in providing the news while allowing for an immersive
          experience. The last key UI feature is News24 optimization for all
          devices The UI is responsive in design as it adjusts to the size of
          the screen. This ensures that users can easily access the website on
          any device. These are the key UI feature that allows for a better user
          experience on the website. This concept is iterated by Interaction
          Design Foundation when they explain the concept of “Good UI”
          (Interaction design foundation 2023)by explaining how UI must be kept
          simple and aligned for the user to that it is easy and simple to use
          while allowing the user to stay focused on the task they have. Thus,
          showing how News24 uses UI successfully for easy and simple user
          interaction and understanding.
        </p>
        <p class="essayText">
          The design of UX and UI can have ethical implications. The ethical
          implication of UX and UI can vary from many options. There is an
          ethical concern about privacy. The UI and UX of News24 in
          personalization use techniques to create the user experience to
          individuals' interests and preferences. Data about the user's location
          or browsing history is gathered to recommend relevant news stories.
          This concept of data used by News24 is evaluated in "The Ethics of
          User Experience Design" where they about how “designers have a
          responsibility to protect user privacy” (Vistisen & Jensen 2021) as
          they talk about how the designers must be transparent with the user
          about the data collected, how it is used, and that the user should be
          able to choose whether to share that data with them or not. In News24,
          they follow this ethical concern of privacy by giving the user the
          option to share their information and in doing so allows them to be
          transparent about the data that is collected from their users, such as
          browsing history or location data, and how it is used. They also give
          users control over their data and opt out of data collection by
          changing those settings. This is protecting user privacy and building
          trust with their use to maintain a positive reputation. This is
          especially important given recent concerns about data breaches and
          misuse of personal information for News websites and applications.
        </p>
        <p class="essayText">
          Along with privacy are the “dangers of distraction” (Geyser 2021) as
          an ethical concern. The danger of distraction refers to how the
          information provided can take focus away from the user from what they
          were doing. Depending on the type of medium the user is on will apply
          different types of distraction. In regards to the website, the
          designers of News24 take into consideration for dangers of distraction
          as this is indicated in their video news as the video does not
          automatically play but rather gives the user an option in which they
          can choose whether to play the video or not. This concept is referred
          to in “The Ethics of User Experience Design" when they state that it
          is “important to design products that respect users' time and
          attention.” (Vistisen & Jensen 2021) which means that the designer
          must always consider what the user will want to do as if they are busy
          and they must respect the user and allow they to choose when they want
          to view the information. For example, if push notifications are
          automatically done it may be more likely to distract users from their
          other important tasks. News24 allows the user to choose when to play a
          video or decide whether they get notifications for a piece of certain
          news, thus showing that News24's UI and UX were designed in an ethical
          manner that can avoid distraction from important tasks.
        </p>
        <p class="essayText">
          Therefore, after a careful analysis of the research discussed through
          the website News24, we have found that the UI and UX of websites use
          manipulation tactics to draw the user into the website, but the fact
          that all the information is provided and that the users have control
          over their experience on the website leaves very little to no ethical
          concern.
        </p>
      </main>
    </section>

    <section class="essays" id="essay2">
      <h2 class="heading">
        <span>Mitigating</span> the Risk of <span>Extinction</span> from
        <span>AI</span>
      </h2>
      <main class="essay-container">
        <p class="essayText">
          The idea that AI and Algorithmic Culture is an indication of the
          pervasive influence of algorithms and AI in various aspects of our
          daily lives, shapes our behaviours, preferences, and experiences. It
          has been said that “Mitigating the risk of extinction from Al should
          be a global priority alongside other societal-scale risks such as
          pandemics and nuclear war.” (Center for Al Safety 2023) By
          investigating systems of digital inequalities, the internet, society,
          design justice, and ethical internet; this essay will attempt to
          justify whether reducing the risks from AI and Algorithmic Culture
          should be a global priority.
        </p>
        <p class="essayText">
          To understand this statement, “Mitigating the risk of extinction from
          Al should be a global priority alongside other societal-scale risks
          such as pandemics and nuclear war.” (Center for Al Safety 2023) Let’s
          break it down to know the extent of its meaning. The first part is
          “Mitigating the risk of extinction” This is focusing on minimizing or
          preventing the possibility of a case in which humanity could cease to
          exist. This statement refers to the potential threat of artificial
          intelligence, which could have catastrophic consequences if not
          controlled. The next aspect in the statement is that it should be a
          “Global priority” implying that the risk of extinction from Al should
          be treated as a matter of importance at a global level. Suggesting
          that governments, and organizations around the world should pay
          attention, resources, and efforts to address this before it can become
          an issue. The next part is “Societal-scale risks” as it compares the
          risk of extinction from Al to other significant risks that impact can
          societies. It mentions pandemics and nuclear war as examples. Thus,
          refer to AI as something that can cause a devastating impact on
          society, like the coronavirus pandemic. These risks are considered
          extremely serious and have the potential to cause significant harm to
          humanity. As it can be seen this statement emphasizes the need to
          prioritize efforts to prevent the risk of extinction from Al, treating
          it as a global concern alongside other risks like pandemics and
          nuclear war. It indicates the importance of recognizing and addressing
          the potential dangers that come with the development of AI, as it
          should be something everyone should be concerned about.
        </p>
        <p class="essayText">
          Before unpacking the risk the potential risk, let us understand why
          and who released this statement. The statement was released by the
          CAIS which stands for Centre for Al Safety. The CAIS is an
          organization that works in equipping individuals, businesses and
          organizations with the tool and understanding of the rapid growth of
          AI and the risks it has. They released this statement that has also
          been signed by large amounts of AI scientists and notable figures,
          executives, professors, leaders, and many others, including, Hinton
          and Yoshua Benzio, two people who have been declared “fathers” of the
          AI revolution. This is important to note as it is an indication of the
          significance of the risks of AI. This also shows the validity of the
          claims that AI has the potential to the extinction of humanity.
        </p>
        <p class="essayText">
          The CAIS explain that “AI risk” is becoming harder to distinguish AI
          content from human-created content. From this content it can “enforce
          bais, power autonomous weapons, promote misinformation, and conduct
          cyberattacks” (Center for Al Safety 2023) even though they use human
          involvement they are increasing to be the ability to “act autonomously
          to cause harm” (Center for Al Safety 2023) This means that AI risk is
          how it is starting to be used in harmful ways which can leave a
          horrifying impact and since it will be learning from this, it can
          start doing it on it own within human interaction.
        </p>
        <p class="essayText">
          Furthermore, we can investigate some of these risks that come with AI
          and Algorithmic Culture to understand why it should be a global
          priority as well as why these figures signed the statement. In Kari
          Paul’s article, the risk of AI and algorithmic culture is not about it
          going all Terminator on us, but rather about how AI algorithmizes and
          programmed, implemented and use to cause and create harm in domains of
          society. This is an indication that these things can affect and
          influence the way individuals perceive and identify aspects of
          society.
        </p>
        <p class="essayText">
          This is seen through the risk of “misinformation.” (Center for Al
          Safety 2023) This is when AI is used as a widespread tool to generate
          misinformation and persuasive content that could have negative
          implications for society, making it less equipped to tackle important
          challenges and potentially leading to a deterioration of
          decision-making and a setback in moral progress. This use of
          misinformation has already started in terms of racial profiling groups
          of individuals, this form of misinformation is also known as
          “technological redlining” (Garrett 2019) as it away in which describes
          how profiling is enacted by algorithmizes on the internet. This is was
          in Safiya Umoja Noble's paper when she typed “Black girls” into Google
          and the result she got was horrifying as they pornographic and racist.
          This is an indication of misinformation using technological redlining
          for radicalization and a setback in society’s morals. As it is
          profiling this group of women and contributing to the radicalization
          of individuals, pushing and influencing individuals towards these
          extreme beliefs or actions of this group of people even though it is
          not accurate towards them. Further, showing how AI and algorithmic
          culture is persuasive in what is shown, which hinders moral progress
          by appealing to people's biases and emotions.
        </p>
        <p class="essayText">
          Furthermore, we can investigate how AI and Algorithmic Culture is
          biased and discriminatory in the aspect of its classification. Al and
          algorithms can perpetuate bias and discrimination when they are
          trained on biased training data or if algorithms are designed with
          implicit biases. These training data sets are used to help AI and
          algorithms to classify individuals based and what is seen. This is
          known as “phrenological impulse” (Getahun 2022) as it categorises
          people based on their appearance and what is visible, this assumes a
          person’s gender, race, and sexuality based on what it sees. This is
          reducing people into binary gender categories, thus it is rendering
          certain people who don’t identify in those categories ‘invisible’.
          This can cause people to feel as if they are felt out as they don’t
          fit in as Al and algorithms are defining the world within the set
          terms. This is important to note as it restricts how individuals can
          be represented and known by giving simplistic labels for a subject as
          complex and delicate as personal identity.
        </p>
        <p class="essayText">
          Alongside misinformation is “Proxy Gaming.” .” (Center for Al Safety
          2023) This refers to how Al and algorithm systems that have been
          programmed with flawed objectives may come up with creative ways to
          achieve their objectives at the expense of personal and community
          values. The flawed objectives of algorithms and AI come in during the
          training phase and this is because they are trained for performance
          and what is most viewed during this performance training, the
          objectives set don’t align with human values as it is about what is
          most viewed and recommended to the system and then it recommends to
          other people and this may not be what is appropriate. (Colome 2023)
          From this, we can understand that AI and algorithms are based on
          performance as in what has been viewed the most or longest and it
          poses the risk as it will start to display that content more often,
          for this system it is harder to distinguish between harmful and
          legitimate content accurately. This was seen in YouTube history, as
          between 2005-2011 algorithms were optimized for clicks & views meaning
          it recommend videos that attracted the most views or click, then in
          2012 it was optimized for watch time as it recommended video that you
          watched the longest and what would keep the user on the platform for
          the longest time. Then in 2016, it was optimized for satisfaction,
          meaning it would show the user what they wanted based on what they
          liked and disliked about the video. ( McLachlan & Cooper 2023) Each of
          these algorithm optimisations was created in showing the user what
          they wanted to see and not both sides of the aspect. Thus, creating an
          influence over the user on what they see and if it is harmful can
          create an impact on the user changing their view on the subject, thus
          it is unethical as it is forcing the user to perceive a subject in a
          certain view even though they don’t know both sides to it.
        </p>
        <p class="essayText">
          Furthermore, along with this proxy gaming comes Filter Bubbles and
          Echo Chambers. This is because AI and algorithmic systems often
          personalize content and recommendations based on user's preferences
          and past behaviours. While this does enhance the user experience by
          giving them what they want to see, it also creates filter bubbles and
          echo chambers, meaning that people are exposed only to information
          that goes with their existing personal beliefs. This contributes to
          the spread of misinformation. As it uses proxy gaming gathers what has
          been viewed the most by the user to effectively show similar content
          which may not be positive, thus it creates a harmful environment as it
          indulges the users in a belief take is harmful to others and
          themselves. It is an indication of how algorithms on the internet are
          effective in displaying what the users want to see but what gives them
          both views on the matter.
        </p>
        <p class="essayText">
          Therefore, after careful analysis of the research discussed, we have
          found that AI and Algorithmic Culture does pose a threat to humanity;
          the fact that it uses their foundation to create biases to
          discriminate against and how display one-sided content to their users
          does not allow them to see the whole picture, indicating that it is
          harmful in shaping and re-enforcing belief of the user no matter how
          harmful. Thus, AI and Algorithmic Culture are justified in being a
          global priority of their potential risk of the extinction of humanity
          through their discriminatory and unethical nature.
        </p>
      </main>
    </section>

    <section class="bib" id="bib">
      <h2 class="heading">Bibliography</h2>
      <main class="bib-container">
        <h3 class="bheading">Essay 1</h3>
        <p class="bibText">
          • Basson, A. 1988. News24. Online.
          <a href="https://www.news24.com/">https://www.news24.com/</a>.
          02/04/2023.<br />• Pavliuchik, K. 2022. Bootcamp. The 12 biggest
          ethical problems every UX/UI Designer should consider. Online.
          <a
            href="https://bootcamp.uxdesign.cc/the-12-biggest-ethical-problems-every-ux-ui-designershould-consider-739d9b39c11b"
            >https://bootcamp.uxdesign.cc/the-12-biggest-ethical-problems-every-ux-ui-designershould-consider-739d9b39c11b</a
          >. 01/04/2023. <br />• Interaction design foundation. 2023.
          Interaction design foundation. User Interface (UI) Design. Online.
          <a
            href="https://www.interaction-design.org/literature/topics/ui-design"
            >https://www.interaction-design.org/literature/topics/ui-design</a
          >
          01/05/2023<br />• Hassenzahl, M. Tractinsky, N. 2006. User experience
          - a research agenda. Behaviour & Information Technology, 25(2),
          91-97.<br />• Vistisen, P. Jensen, T. 2021. The ethics of user
          experience design. Ethics and Information Technology, 23(2),
          89-100.<br />• Geyser, H. 2021. ETHICS OF UX PRACTICE. 3 April 2023.
          Lecture notes. The University of the Witwatersrand.<br />•
          DICTIONARY.COM: ethics. 2023. 3rd edition. Boston: Houghton Mifflin
          Harcourt Publishing Company.
        </p>

        <h3 class="bheading">Essay 2</h3>
        <p class="bibText">
          • Garrett, C, Y. 2019. Review of Algorithms of Oppression: How Search
          Engines Reinforce Racism: Journal of Contemporary Archival Studies
          6(8). Drew University. <br />
          • Center for Al Safety. 2023. CENTER FOR AI SAFETY. Online.
          <a href="https://www.safe.ai/about">https://www.safe.ai/about</a> Date
          Accessed 17/06/2023 <br />
          • Paul, A. 2023. POPULAR SCIENCE. Big Tech's latest Al doomsday
          warning might be more of the same hype. Online.
          <a href="https://www.popsci.com/technology/ai-warning-critics/"
            >https://www.popsci.com/technology/ai-warning-critics/</a
          >
          Date Accessed 17/06/2023 <br />
          • Colome, P, J. 2023. EL PAIS. Why are the people who pushed for
          artificial intelligence now signing so many doomsday manifestos?
          Online.
          <a
            href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html"
            >https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html</a
          >
          Date Accessed 17/06/2023 <br />
          • Paul, K. 2023. The Guardian. Robot takeover? Not quite. Here's what
          AI doomsday would look like. Online.
          <a
            href="https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears"
            >https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears</a
          >
          Date Accessed 17/06/2023 <br />
          • Getahun, H. 2022. INSIDER. Should Al be used to classify humans? An
          Al researcher at USC says it's reductive and ethically dubious.
          Online.
          <a
            href="https://www.businessinsider.com/interview-kate-crawford-ethics-of-using-ai-to-categorize-people-2022-12"
            >https://www.businessinsider.com/interview-kate-crawford-ethics-of-using-ai-to-categorize-people-2022-12</a
          >
          Date Accessed 17/06/2023 <br />
          • McLachlan, S & Cooper, P. 2023. Hootsuite. How the YouTube Algorithm
          Works in 2023: The Complete Guide. Online.
          <a href="https://blog.hootsuite.com/how-the-youtube-algorithm-works/"
            >https://blog.hootsuite.com/how-the-youtube-algorithm-works/</a
          >
          Date Accessed 17/06/2023 <br />
          • Hao, K. 2019. MIT Technology Review. DeepMind is asking how Al
          helped turn the internet into an echo chamber. Online.
          <a
            href="https://www.technologyreview.com/2019/03/07/65984/deepmind-is-asking-how-google-helped-turn-the-internet-into-an-echo-chamber/"
            >https://www.technologyreview.com/2019/03/07/65984/deepmind-is-asking-how-google-helped-turn-the-internet-into-an-echo-chamber/</a
          >
          Date Accessed 17/06/2023
        </p>
      </main>
    </section>

    <footer>
      <script id="replace_with_footer" src="../js/nav.js"></script>
    </footer>
  </body>
  <script src="../js/nav.js"></script>
  <script src="../js/script.js"></script>
  <script src="../js/secondarynav.js"></script>
</html>
